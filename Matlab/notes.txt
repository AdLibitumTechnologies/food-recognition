http://cs231n.github.io/transfer-learning/
Transfer learning - use ConvNet as an initialization or a fixed feature extractor for the task of interest

1. ConvNet as fixed feature extractor
	- take a ConvNet pretrained on ImageNet, remove the last layer that contains the output for 1000 class scores
	- Treat the rest of the ConvNet as a fixed feature extractor for the new dataset
	- The ConvNet will compute a 4096-D vector for every image that contains the activations of the hidden layer immediately before the classifier (CNN codes)
	- Ensure that the codes are ReLUd (thresholded at zero)
	- Train a linear classifier (Linear SVM or Softmax) for the new dataset

2. Fine-tuning the ConvNet
	- replace and retrain the classifier on top of the ConvNet on the new dataset
	- fine-tune the weights of the pretrained network by continuting backpropogation
	- optional to choose to keep some layers fixed and only fine tune higher-level portion of the network (early layers contain generic features, later layers are more specific to the original dataset)


Deciding on which Transfer Learning to use
1. New dataset is small, and similar to original dataset ---> Linear classifier on CNN codes
2. New dataset is large and similar to original dataset ---> more confidence to fine-tune through the full network
3. Net dataset is small but very different from the original dataset ---> train SVM classifier from activations somewhere earlier in the network
4. New dataset is large and very different ---> fine-tune through the entire network

Transfer Learning Constraints:
- premodels constrain the architecture (padding, strides etc...)
- we assume the ConvNet weights are good, we don't want to distort them quickly or too much. USE SMALL LEARNING RATES!!

---- CNN Architecture -----
INPUT [32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R,G,B.
CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and the region they are connected to in the input volume. This may result in volume such as [32x32x12].
RELU layer will apply an elementwise activation function, such as the max(0,x)max(0,x) thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]).
POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12].
FC (i.e. fully-connected) layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score, such as among the 10 categories of CIFAR-10. As with ordinary Neural Networks and as the name implies, each neuron in this layer will be connected to all the numbers in the previous volume.


To Do:
√ Use GoogleNet, change the last layer to SVM
√ Compare it with the original Softmax
√ Show the intermediate filters/outputs
- Try with more classes (add in 20 more classes)
- Rerun all the classifiers, this time with the time, analyze the run time
√ Get the images that have been mistakenly classified and check if those images contain more than one object or wrong from the ground truth


Benchmark:
90 classes - top 1 (accuracy 76%)



Additional References
- CNN Features off-the-shelf: an Astounding Baseline for Recognition trains SVMs on features from ImageNet-pretrained ConvNet and reports several state of the art results.
- DeCAF reported similar findings in 2013. The framework in this paper (DeCAF) was a Python-based precursor to the C++ Caffe library.
- How transferable are features in deep neural networks? studies the transfer learning performance in detail, including some unintuitive findings about layer co-adaptations.